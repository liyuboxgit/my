spark
	download spark in http://spark.apache.org/
	tar -xf spark*.tar
	bin/spark-shell
	in shell>
		spark.read.textFile("README.md").count() //return 205
spark-sql
	bin/spark-shell bin/spark-shell --jars /usr/local/mysql/mysql-test/jdbc/mysql-connector-java-5.1.44.jar 
	val jdbcDF = spark.read.format("jdbc").option("url", "jdbc:mysql://localhost:3306/mysql").option("dbtable", "user").option("user", "root").option("password", "liyuff").load()
	#jdbcDF.show()
	jdbcDF.registerTempTable("test")
	jdbcDF.sqlContext.sql("select user from test").collect.foreach(println)
	jdbcDF.toJavaRDD.coalesce(1).saveAsTextFile("temppath")
	jdbcDF.sqlContext.sql("select user,host from test").toJavaRDD.coalesce(1).saveAsTextFile("temppath")

sqoop
	#连接查看mysql
	bin/sqoop list-tables --username root --password 'liyuff' --connect jdbc:mysql://localhost:3306/mysql?characterEncoding=UTF-8
	#创建hive表
	bin/sqoop create-hive-table --connect jdbc:mysql://localhost:3306/sqoop_hive?characterEncoding=UTF-8 --table test --username root -password 'liyuff' --hive-database sqoop_hive
	#mysql数据导入hive
	bin/sqoop import --connect jdbc:mysql://localhost:3306/sqoop_hive?characterEncoding=UTF-8 --table test --username root -password  'liyuff' --fields-terminated-by ',' --hive-import --hive-database sqoop_hive  -m  1
	导入数据全为null（待解决）
