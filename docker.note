doc	ker
	1，安装
	uname -r #查看linux内核版本，高于3.10才可以安装docker
	yum update #需要先更新一下
    yum remove docker  docker-common docker-selinux docker-engine #如果安装过，先卸载
    yum -y install yum-utils #为执行下一行命令
    yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
    yum list docker-ce --showduplicates | sort -r #查看版本
    yum install docker-ce 安装
    systemctl start docker 启动
    docker version 
	#执行docker version有下面两部分说明安装成功,如报prior storage driver devicemapper failed: Device is Busy，执行yum update xfsprogs
		Client:
		 Version:           18.09.4
		 API version:       1.39
		 Go version:        go1.10.8
		 Git commit:        d14af54266
		 Built:             Wed Mar 27 18:34:51 2019
		 OS/Arch:           linux/amd64
		 Experimental:      false

		Server: Docker Engine - Community
		 Engine:
		  Version:          18.09.4
		  API version:      1.39 (minimum version 1.12)
		  Go version:       go1.10.8
		  Git commit:       d14af54
		  Built:            Wed Mar 27 18:04:46 2019
		  OS/Arch:          linux/amd64
		  Experimental:     false
	2，启动和关闭
	systemctl start docker
	systemctl stop docker
	3，使用mysql(docker mysql)
	docker images #查询本地镜像
	docker pull mysql:5.7 #拉取镜像
	docker run -d -i -p 3306:3306 --name=mysql --restart=no -e MYSQL_ROOT_PASSWORD=liyuff -d mysql:5.7 #启动容器(外部机器连接容器可能需要关闭防火墙)
	docker ps -a #列出所有容器
	docker ps -s #列出成功运行的容器
	docker stop $CONTAINER_ID #停止容器，CONTAINER_ID从上一个命令中获取
	docker rm --force $CONTAINER_ID #移除容器(不能停止的容器要使用forch参数)
		docker rm `docker ps -a -q` 或者 docker rm -f $(docker ps -a -q) #移除所有容器
	docker rmi $image_id #删除镜像(image_id从docker images获取)
	
	导出镜像
	docker save > nginx.tar zookeeper:latest
	导入镜像
	docker load < zookeeper.tar
	
	通过修改启动脚本配置加速站点
	vim /usr/lib/systemd/system/docker.service 
	ExecStart=/usr/bin/dockerd --registry-mirror=https://3laho3y3.mirror.aliyuncs.com/
	
	docker进入容器，CONTAINER_ID从docker ps中获取
	docker exec -it $CONTAINER_ID /bin/bash
	
	docker双向拷贝
	docker cp $CONTAINER_ID:/xx ./
	
	docker执行java命令
	docker run java java -version
	
	docker文件挂载
	docker run -v "$PWD":/root -w /root java java T //将当前目录挂载到镜像/root目录，并进入该目录，运行java容器，执行java命令java T
	chmod 0777 data/ -R && chmod 0777 logs/ -R //如果挂载出现权限问题，可以如此授权
	docker run -d -v /root/data/:/usr/share/elasticsearch/data -v /root/logs/:/usr/share/elasticsearch/logs -p 9200:9200 --privileged=true elasticsearch:6.5.0 //示例
	
	docker日志跟踪
	docker logs -f 42dq //容器id随机串的前几位
	
	docker安装nginx容器:docker run --name nginx -p 80:80 -p 443:443 -v /data/cloudpivot/program/frontEnd:/usr/share/nginx/html -v /data/cloudpivot/middleware/nginx/conf/nginx.conf:/etc/nginx/nginx.conf --privileged=true -v /data/cloudpivot/middleware/nginx/log:/var/log/nignx -v /data/cloudpivot/middleware/nginx/ssl/:/etc/nginx/ssl/:rw  --restart=always -d nginx:latest
	docker安装redis容器:docker run --name redis -p6379:6379 --restart=always -d redis:4-alpine3.8 --requirepass "H3yuncom"
	docker安装zk容器   :docker run --name zk -p2181:2181 --restart=always -d zookeeper:latest
	docker安装mysql容器:docker run -itd --name mysql -v /data/cloudpivot/middleware/mysql/mysql-data/:/var/lib/mysql -v /data/cloudpivot/middleware/mysql/conf/my.cnf:/etc/mysql/my.cnf --privileged=true -e MYSQL_ROOT_PASSWORD=test123456 -p 3306:3306 --restart=always mysql:5.7
	
	iptables查看端口映射
	iptables -t nat -L -n
	DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:6379 to:172.21.0.2:6379
	DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:3301 to:172.21.0.3:3306  	//myslq的容器，启动3306端口，映射外网的3301端口，3301可以用任何工具去连接 
																									//配置端口映射，容器的默认端口不能变，除非提供配置文件。否则很难排查出问题所在。
	DNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:8888 to:172.21.0.4:8888

	
	构建镜像
	vi Dockerfile
	From nginx
	RUN echo 'welcome'>/usr/share/nginx/html/index.html
	docker built -t nginx:my .
	构建镜像2
	###基础镜像
	FROM contos-jdk
	#WORKDIR指令用于指定容器的一个目录， 容器启动时执行的命令会在该目录下执行。
	WORKDIR /
	###将可运行jar复制到容器根目录下
	ADD cloudpivot-engine-bootstartup-1.5.0-alpha.24.6.jar cloudpivot-engine-bootstartup-1.5.0-alpha.24.6.jar
	ADD application-prod.yml application-prod.yml
	ADD engine-logs /engine-logs
	###暴露容器端口为8080 Docker镜像告知Docker宿主机应用监听了8080端口
	EXPOSE 8080
	###设置环境变量
	ENV JAVA_OPTS="\
	-server \
	-Xmx1024m \
	-Xms1024m \
	-Xss256k \
	-XX:MetaspaceSize=512m \
	-XX:MaxMetaspaceSize=512m \
	-XX:+UseParallelGC \
	-XX:ParallelGCThreads=4 \
	-XX:+UseParallelOldGC \
	-XX:+UseAdaptiveSizePolicy \
	-XX:+PrintGCDetails \
	-XX:+PrintTenuringDistribution \
	-XX:+PrintGCTimeStamps \
	-XX:+HeapDumpOnOutOfMemoryError \
	-XX:HeapDumpPath=/ \
	-Xloggc:/gc.log \
	-XX:+UseGCLogFileRotation \
	-XX:NumberOfGCLogFiles=5 \
	-XX:GCLogFileSize=10M"
	#容器启动时执行的命令
	CMD java -jar cloudpivot-engine-bootstartup-1.5.0-alpha.24.6.jar --spring.profiles.active=prod
	#构建镜像命令
	docker build -t engine:24.6 .
	#运行镜像
	docker run -it --name engine -p 8099:8099 --privileged=true -v /devops/log/engine:/engine-logs/ engine:24.6

	maven构建镜像
	<plugin>
		<groupId>com.spotify</groupId>
		<artifactId>docker-maven-plugin</artifactId>
		<version>0.4.12</version>
		<configuration>
			<imageName>eureka-server:0.0.1</imageName>
			<baseImage>tomcat</baseImage>
			<entryPoint>["java", "-jar", "/${project.build.finalName}.jar"]</entryPoint>
			<resources>
				<resource>
					<targetPath>/</targetPath>
					<directory>${project.build.directory}</directory>
					<include>${project.build.finalName}.jar</include>
				</resource>
			</resources>
		</configuration>
	</plugin>
	..
	<finalName>eureka-server</finalName>
	mvn clean package docker:build
	docker run -d -p 80:8762 eureka-server:0.0.1
	docker logs --since 30 $CONTAINER_ID
	
	docker-compose编排
	curl -L https://github.com/docker/compose/releases/download/1.21.2/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose
	chmod +x /usr/local/bin/docker-compose
	docker-compose -v

	touch Dockerfile
	vim Dockerfile 

	touch docker-compose.yml
	vi docker-compose.yml 
	/usr/local/apache-maven-3.6.1/bin/mvn clean package
	docker-compose up 
  
	docker-compose编排微服务
	各服务运行maven生成镜像：mvn clean package docker:build
	查看镜像：docker images
	编写docker-compose.yml文件：
	version: '2'
	services:
	  eureka-server:
		image: liyu/eureka-server:0.0.1-SNAPSHOT
		ports:
		  - "8762:8762"

	  eureka-provider:
		image: liyu/eureka-provider:0.0.1-SNAPSHOT
		links:
		  - eureka-server:liyu

	  eureka-consumer:
		image: liyu/eureka-consumer:0.0.1-SNAPSHOT
		ports:
		  - "10002:10002"
		links:
		  - eureka-server:liyu
	注意expose参数
	运行镜像：docker-compose up
	动态扩容：docker-compose scale eureka-provider=3
	在服务注册首页可见：
	EUREKA-CONSUMER	n/a (1)	(1)	UP (1) - 184463db264e:eureka-consumer:10002
	EUREKA-PROVIDER	n/a (3)	(3)	UP (3) - e6cdf0f76cfe:eureka-provider:10001 , 6a9e4ed2bec8:eureka-provider:10001 , 0e400b56161e:eureka-provider:10001
	
k8s集群安装	
	https://www.kubernetes.org.cn/5462.html	
	注：在所有节点上进行如下操作

	1.设置主机名hostname，管理节点设置主机名为 master 。
	hostnamectl set-hostname master
	需要设置其他主机名称时，可将 master 替换为正确的主机名node1、node2即可。

	2.编辑 /etc/hosts 文件，添加域名解析。
	cat <<EOF >>/etc/hosts
	10.10.10.10 master
	10.10.10.11 node1
	10.10.10.12 node2
	EOF

	3.关闭防火墙、selinux和swap。
	systemctl stop firewalld
	systemctl disable firewalld
	setenforce 0
	sed -i "s/^SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config
	swapoff -a
	sed -i 's/.*swap.*/#&/' /etc/fstab

	4.配置内核参数，将桥接的IPv4流量传递到iptables的链
	cat > /etc/sysctl.d/k8s.conf <<EOF
	net.bridge.bridge-nf-call-ip6tables = 1
	net.bridge.bridge-nf-call-iptables = 1
	EOF
	sysctl --system

	5.配置国内yum源
	yum install -y wget
	mkdir /etc/yum.repos.d/bak && mv /etc/yum.repos.d/*.repo /etc/yum.repos.d/bak
	wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.cloud.tencent.com/repo/centos7_base.repo
	wget -O /etc/yum.repos.d/epel.repo http://mirrors.cloud.tencent.com/repo/epel-7.repo
	yum clean all && yum makecache
	配置国内Kubernetes源
	cat <<EOF > /etc/yum.repos.d/kubernetes.repo
	[kubernetes]
	name=Kubernetes
	baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
	enabled=1
	gpgcheck=1
	repo_gpgcheck=1
	gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
	EOF
	配置 docker 源
	wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo

	三、软件安装

	注：在所有节点上进行如下操作

	1.安装docker(安装此版本的docker可能会有问题，安装本文件上面的方式安装docker)
	yum install -y docker-ce-18.06.1.ce-3.el7
	systemctl enable docker && systemctl start docker
	docker –version
	Docker version 18.06.1-ce, build e68fc7a
	docker服务为容器运行提供计算资源，是所有容器运行的基本平台。

	2.安装kubeadm、kubelet、kubectl
	yum install -y kubelet kubeadm kubectl
	systemctl enable kubelet
	Kubelet负责与其他节点集群通信，并进行本节点Pod和容器生命周期的管理。
	Kubeadm是Kubernetes的自动化部署工具，降低了部署难度，提高效率。
	Kubectl是Kubernetes集群管理工具。

	四、部署master 节点

	注：在master节点上进行如下操作

	1.在master进行Kubernetes集群初始化(定义ubernetes-version=1.14.2可能会安装失败，去掉就ok了)。
	kubeadm init --kubernetes-version=1.14.2 \
	--apiserver-advertise-address=10.10.10.10 \
	--image-repository registry.aliyuncs.com/google_containers \
	--service-cidr=10.1.0.0/16 \
	--pod-network-cidr=10.244.0.0/16
	定义POD的网段为: 10.244.0.0/16， api server地址就是master本机IP地址。
	这一步很关键，由于kubeadm 默认从官网k8s.grc.io下载所需镜像，国内无法访问，因此需要通过–image-repository指定阿里云镜像仓库地址，很多新手初次部署都卡在此环节无法进行后续配置。
	集群初始化成功后返回如下信息：
	记录生成的最后部分内容，此内容需要在其它节点加入Kubernetes集群时执行。

	kubeadm join 10.10.10.10:6443 --token kekvgu.nw1n76h84f4camj6 \

	--discovery-token-ca-cert-hash sha256:4ee74205227c78ca62f2d641635afa4d50e6634acfaa8291f28582c7e3b0e30e

	2.配置kubectl工具

	mkdir -p /root/.kube
	cp /etc/kubernetes/admin.conf /root/.kube/config
	kubectl get nodes
	kubectl get cs

	3.部署flannel网络
	kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml

	五、部署node节点

	注：在所有node节点上进行如下操作
	执行如下命令，使所有node节点加入Kubernetes集群
	kubeadm join 10.10.10.10:6443 --token kekvgu.nw1n76h84f4camj6 \

	--discovery-token-ca-cert-hash sha256:4ee74205227c78ca62f2d641635afa4d50e6634acfaa8291f28582c7e3b0e30e

	此命令为集群初始化时（kubeadm init）返回结果中的内容。

	六、集群状态检测

	注：在master节点上进行如下操作
	1.在master节点输入命令检查集群状态，返回如下结果则集群状态正常。
	kubectl get nodes
	NAME     STATUS   ROLES    AGE     VERSION
	master   Ready    master   26m     v1.14.2
	node1    Ready    <none>   3m10s   v1.14.2
	node2    Ready    <none>   3m      v1.14.2

	重点查看STATUS内容为Ready时，则说明集群状态正常。

	2.创建Pod以验证集群是否正常。

	kubectl create deployment nginx --image=nginx
	kubectl expose deployment nginx --port=80 --type=NodePort
	kubectl get pod,svc

	七、部署Dashboard

	注：在master节点上进行如下操作

	1.创建Dashboard的yaml文件
	wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml
	sed -i 's/k8s.gcr.io/loveone/g' kubernetes-dashboard.yaml
	sed -i '/targetPort:/a\ \ \ \ \ \ nodePort: 30001\n\ \ type: NodePort' kubernetes-dashboard.yaml

	2.部署Dashboard
	kubectl create -f kubernetes-dashboard.yaml

	3.创建完成后，检查相关服务运行状态
	kubectl get deployment kubernetes-dashboard -n kube-system
	kubectl get pods -n kube-system -o wide
	kubectl get services -n kube-system
	netstat -ntlp|grep 30001

	4.在Firefox浏览器输入Dashboard访问地址：https://10.10.10.10:30001

	5.查看访问Dashboard的认证令牌

	kubectl create serviceaccount  dashboard-admin -n kube-system
	kubectl create clusterrolebinding  dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin
	kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk '/dashboard-admin/{print $1}')

	单机版上命令：https://blog.csdn.net/u013355826/article/details/82801482	
	journalctl -f -u kubelet
	swapoff -a	
	systemctl status|enable|start kubelet	
	systemctl status|enable|start docker

	kubectl get cs
	kubectl get service
	kubectl get pod

helm安装
	cd /usr/local
	wget https://get.helm.sh/helm-v2.14.3-linux-amd64.tar.gz 
	tar -zxvf helm-v2.14.3-linux-amd64.tar.gz
	mv linux-amd64/helm /usr/local/bin/helm
	helm init --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.14.3 --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
	helm version 
	helm search
	helm repo list
	helm install stable/mysql #helm delete imprecise-seagull
	解决Error: no available release name found
	kubectl create serviceaccount --namespace kube-system tiller
	kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
	kubectl patch deploy --namespace kube-system tiller-deploy -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'
	正确返回：
	NAME:   imprecise-seagull
	LAST DEPLOYED: Sun Mar 15 21:53:17 2020
	NAMESPACE: default
	STATUS: DEPLOYED

	RESOURCES:
	==> v1/PersistentVolumeClaim
	NAME                     STATUS   VOLUME  CAPACITY  ACCESS MODES  STORAGECLASS  AGE
	imprecise-seagull-mysql  Pending  0s

	==> v1/Pod(related)
	NAME                                      READY  STATUS   RESTARTS  AGE
	imprecise-seagull-mysql-645d94b8f5-htd7t  0/1    Pending  0         0s

	==> v1/Secret
	NAME                     TYPE    DATA  AGE
	imprecise-seagull-mysql  Opaque  2     0s

	==> v1/Service
	NAME                     TYPE       CLUSTER-IP   EXTERNAL-IP  PORT(S)   AGE
	imprecise-seagull-mysql  ClusterIP  10.1.96.121  <none>       3306/TCP  0s

	==> v1beta1/Deployment
	NAME                     READY  UP-TO-DATE  AVAILABLE  AGE
	imprecise-seagull-mysql  0/1    1           0          0s


	NOTES:
	MySQL can be accessed via port 3306 on the following DNS name from within your cluster:
	imprecise-seagull-mysql.default.svc.cluster.local

	To get your root password run:

		MYSQL_ROOT_PASSWORD=$(kubectl get secret --namespace default imprecise-seagull-mysql -o jsonpath="{.data.mysql-root-password}" | base64 --decode; echo)

	To connect to your database:

	1. Run an Ubuntu pod that you can use as a client:

		kubectl run -i --tty ubuntu --image=ubuntu:16.04 --restart=Never -- bash -il

	2. Install the mysql client:

		$ apt-get update && apt-get install mysql-client -y

	3. Connect using the mysql cli, then provide your password:
		$ mysql -h imprecise-seagull-mysql -p

	To connect to your database directly from outside the K8s cluster:
		MYSQL_HOST=127.0.0.1
		MYSQL_PORT=3306

		# Execute the following commands to route the connection:
		export POD_NAME=$(kubectl get pods --namespace default -l "app=imprecise-seagull-mysql" -o jsonpath="{.items[0].metadata.name}")
		kubectl port-forward $POD_NAME 3306:3306

		mysql -h ${MYSQL_HOST} -P${MYSQL_PORT} -u root -p${MYSQL_ROOT_PASSWORD}
	
	helm之char结构
	[root@k8s ~]# tar -tvf ./.helm/cache/archive/mysql-0.3.5.tgz
	-rwxr-xr-x 0/0             420 1969-12-31 19:00 mysql/Chart.yaml
	-rwxr-xr-x 0/0            1970 1969-12-31 19:00 mysql/values.yaml
	-rwxr-xr-x 0/0            1719 1969-12-31 19:00 mysql/templates/NOTES.txt
	-rwxr-xr-x 0/0             528 1969-12-31 19:00 mysql/templates/_helpers.tpl
	-rwxr-xr-x 0/0             240 1969-12-31 19:00 mysql/templates/configmap.yaml
	-rwxr-xr-x 0/0            3901 1969-12-31 19:00 mysql/templates/deployment.yaml
	-rwxr-xr-x 0/0             733 1969-12-31 19:00 mysql/templates/pvc.yaml
	-rwxr-xr-x 0/0             654 1969-12-31 19:00 mysql/templates/secrets.yaml
	-rwxr-xr-x 0/0             539 1969-12-31 19:00 mysql/templates/svc.yaml
	-rwxr-xr-x 0/0               5 1969-12-31 19:00 mysql/.helmignore
	-rwxr-xr-x 0/0            7366 1969-12-31 19:00 mysql/README.md


时间同步
	timedatectl set-timezone Asia/Shanghai
	yum install -y ntp
	ntpdate -u cn.pool.ntp.org
	
普罗米修斯监控：https://www.cnblogs.com/afterdawn/p/9020129.html
	in /usr/local install
	  node_exporter
	  prometheus
	start
	  ./node_exporter &
	  ./prometheus &
	ui
	  http://192.168.43.58:9100/metrics
	  http://192.168.43.58:9090

docker私服
	//拉取镜像
	docker pull docker.io/registry
	//启动容器
	docker run -d -p 5000:5000 --name=registry --restart=always \
		--privileged=true \
		--log-driver=none \
		-v /root/registry/registrydata:/var/lib/registry \
		registry

	//拉取jdk镜像
	docker pull openjdk
	docker run openjdk java -version
	
	//打标
	docker tag openjdk:latest localhost:5000/java:open12.0.2
	//上传镜像到私服
	docker push localhost:5000/java:open12.0.2
	//删除local镜像 
	docker rmi localhost:5000/java:open12.0.2 -f
	//拉取镜像from私服
	docker pull localhost:5000/java:open12.0.2
------------------------------------------------------------------------------->>单机kubernets
#文档地址
https://blog.csdn.net/Gordon_luo/article/details/92804536
#删除原有的安装软件
yum remove docker \
docker-client \
docker-client-latest \
docker-common \
docker-latest \
docker-latest-logrotate \
docker-logrotate \
docker-engine
#安装依赖软件
yum install -y yum-utils \
device-mapper-persistent-data \
lvm2
#增加docker源
yum-config-manager \
--add-repo \
https://download.docker.com/linux/centos/docker-ce.repo
#查看docker历史版本
# yum list docker-ce --showduplicates | sort -r
#安装docker
yum install docker-ce-18.09.1
#设置kubernetes源
cat >>/etc/yum.repos.d/kubernetes.repo <<EOF
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF
#下载镜像文件，运行
#!/bin/bash
set -e
KUBE_VERSION=v1.14.1
KUBE_PAUSE_VERSION=3.1
DASHBOARD_VERSION=v1.10.1
ETCD_VERSION=3.3.10
CORE_DNS_VERSION=1.3.1
GCR_URL=k8s.gcr.io
LUN_URL=docker.io/temmokustar
​
images=(kube-proxy:${KUBE_VERSION}
kube-scheduler:${KUBE_VERSION}
kube-controller-manager:${KUBE_VERSION}
kube-apiserver:${KUBE_VERSION}
kubernetes-dashboard-amd64:${DASHBOARD_VERSION}
pause:${KUBE_PAUSE_VERSION}
etcd:${ETCD_VERSION}
coredns:${CORE_DNS_VERSION})
​
for imageName in ${images[@]};do
  docker pull $LUN_URL/$imageName
  docker tag  $LUN_URL/$imageName $GCR_URL/$imageName
  docker rmi $LUN_URL/$imageName
done
#设置开机启动
systemctl enable docker.service
#配置
{
  "exec-opts": ["native.cgroupdriver=systemd"]
}
#配置
cat >> /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
#配置
cat >/etc/sysconfig/kubelet<<EOF
KUBELET_EXTRA_ARGS=--fail-swap-on=false
EOF
#安装kubernets
yum install -y kubelet-1.14.1 kubeadm-1.14.1 kubectl-1.14.1
#安装kubernets（失败日志，两种处理1:swapoff -a, 2:echo "1" >/proc/sys/net/bridge/bridge-nf-call-iptables, 3:systemctl enable kubelet.service）
kubeadm init --kubernetes-version=v1.14.1 \
--service-cidr=10.1.0.0/16 \
--pod-network-cidr=10.244.0.0/16
#配置
$ mkdir -p $HOME/.kube
$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$ sudo chown $(id -u):$(id -g) $HOME/.kube/config
#测试
kubectl get componentstatus
#按装网络(失败，用wget)
kubectl apply -f \
https://docs.projectcalico.org/v3.6/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml
#一段时间后，全部为running
kubectl get pod -n kube-system -o wide
#将master加入节点
kubectl taint node <MasterHostname> node-role.kubernetes.io/master-
===========================================================================================k8s配置文件
k8s 配置文件 详解
apiVersion: v1 # 【必须】版本号
kind: Pod # 【必选】Pod
metadata: # 【必选-Object】元数据
  name: String # 【必选】 Pod的名称
  namespace: String # 【必选】 Pod所属的命名空间
  labels: # 【List】 自定义标签列表
    - name: String
  annotations: # 【List】 自定义注解列表
    - name: String
spec: # 【必选-Object】 Pod中容器的详细定义
  containers: # 【必选-List】 Pod中容器的详细定义
    - name: String # 【必选】 容器的名称
      image: String # 【必选】 容器的镜像名称
      imagePullPolicy: [Always | Never | IfNotPresent] # 【String】 每次都尝试重新拉取镜像 | 仅使用本地镜像 | 如果本地有镜像则使用，没有则拉取
      command: [String] # 【List】 容器的启动命令列表，如果不指定，则使用镜像打包时使用的启动命令
      args: [String] # 【List】 容器的启动命令参数列表
      workingDir: String # 容器的工作目录
      volumeMounts: # 【List】 挂载到容器内部的存储卷配置
        - name: String # 引用Pod定义的共享存储卷的名称，需使用volumes[]部分定义的共享存储卷名称
          mountPath: Sting # 存储卷在容器内mount的绝对路径，应少于512个字符
          readOnly: Boolean # 是否为只读模式，默认为读写模式
      ports: # 【List】 容器需要暴露的端口号列表
        - name: String  # 端口的名称
          containerPort: Int # 容器需要监听的端口号
          hostPort: Int # 容器所在主机需要监听的端口号，默认与containerPort相同。设置hostPort时，同一台宿主机将无法启动该容器的第二份副本
          protocol: String # 端口协议，支持TCP和UDP，默认值为TCP
      env: # 【List】 容器运行前需设置的环境变量列表
        - name: String # 环境变量的名称
          value: String # 环境变量的值
      resources: # 【Object】 资源限制和资源请求的设置
        limits: # 【Object】 资源限制的设置
          cpu: String # CPU限制，单位为core数，将用于docker run --cpu-shares参数
          memory: String # 内存限制，单位可以为MB，GB等，将用于docker run --memory参数
        requests: # 【Object】 资源限制的设置
          cpu: String # cpu请求，单位为core数，容器启动的初始可用数量
          memory: String # 内存请求，单位可以为MB，GB等，容器启动的初始可用数量
      livenessProbe: # 【Object】 对Pod内各容器健康检查的设置，当探测无响应几次之后，系统将自动重启该容器。可以设置的方法包括：exec、httpGet和tcpSocket。对一个容器只需要设置一种健康检查的方法
        exec: # 【Object】 对Pod内各容器健康检查的设置，exec方式
          command: [String] # exec方式需要指定的命令或者脚本
        httpGet: # 【Object】 对Pod内各容器健康检查的设置，HTTGet方式。需要指定path、port
          path: String
          port: Number
          host: String
          scheme: String
          httpHeaders:
            - name: String
              value: String
        tcpSocket: # 【Object】 对Pod内各容器健康检查的设置，tcpSocket方式
          port: Number
        initialDelaySeconds: Number # 容器启动完成后首次探测的时间，单位为s
        timeoutSeconds: Number  # 对容器健康检查的探测等待响应的超时时间设置，单位为s，默认值为1s。若超过该超时时间设置，则将认为该容器不健康，会重启该容器。
        periodSeconds: Number # 对容器健康检查的定期探测时间设置，单位为s，默认10s探测一次
        successThreshold: 0
        failureThreshold: 0
      securityContext:
        privileged: Boolean
  restartPolicy: [Always | Never | OnFailure] # Pod的重启策略 一旦终止运行，都将重启 | 终止后kubelet将报告给master，不会重启 | 只有Pod以非零退出码终止时，kubelet才会重启该容器。如果容器正常终止（退出码为0），则不会重启。
  nodeSelector: object # 设置Node的Label，以key:value格式指定，Pod将被调度到具有这些Label的Node上
  imagePullSecrets: # 【Object】 pull镜像时使用的Secret名称，以name:secretkey格式指定
    - name: String
  hostNetwork: Boolean # 是否使用主机网络模式，默认值为false。设置为true表示容器使用宿主机网络，不再使用docker网桥，该Pod将无法在同一台宿主机上启动第二个副本
  volumes: # 【List】 在该Pod上定义的共享存储卷列表
    - name: String # 共享存储卷的名称，volume的类型有很多emptyDir，hostPath，secret，nfs，glusterfs，cephfs，configMap
      emptyDir: {} # 【Object】 类型为emptyDir的存储卷，表示与Pod同生命周期的一个临时目录，其值为一个空对象：emptyDir: {}
      hostPath: # 【Object】 类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录
        path: String # Pod所在主机的目录，将被用于容器中mount的目录
      secret: # 【Object】类型为secret的存储卷，表示挂载集群预定义的secret对象到容器内部
        secretName: String
        items:
          - key: String
            path: String
      configMap: # 【Object】 类型为configMap的存储卷，表示挂载集群预定义的configMap对象到容器内部
        name: String
        items:
          - key: String
            path: String




	